<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Learning Dexterity at Human Scale">
  <meta name="keywords" content="Robot Learning, Dexterous Manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning Dexterity at Human Scale</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!--<script defer src="./static/js/fontawesome.all.min.js"></script>-->
  <script src="https://kit.fontawesome.com/8a0d0cac45.js" crossorigin="anonymous"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Learning Dexterity at Human Scale</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"> Under Submission</span>
            </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We propose Baton, a robot learning system that scales dexterous 
              robot manipulation through passive human data collection. Collecting large-scale, 
              real-world data is a long-standing problem in robot learning. Current solutions 
              rely on teleoperation, which is prohibitive at scale due to robot deployment and 
              operational latency. Instead, we show that data collection directly from humans 
              is a scalable alternative. For the first time, we are able to explore generalizaion 
              properties and scaling laws of dexterous policies while collecting as little as one 
              hour of data per task. Our untethered setup, requiring only motion capture gloves 
              and a camera, allows individuals to record accurate hand movements while naturally 
              performing a wide range of manipulation tasks. Across all tasks, Baton 
              averages a throughput of over 400 high-quality demos / hour, a 9.85x speedup 
              over VR teleoperation. We design novel keypoint state representations and train 
              closed-loop morphology-agnostic policies to model 3D fingertip coordinates. 
              We deploy our policies on an Allegro Hand mounted on a Franka Arm and demonstrate 
              generalization over diverse object poses for all tasks.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/teaser.png" alt="Abstract Image" style="max-width: 100%; height: auto;">
            <p class="is-size-6 has-text-grey">Baton scales dexterous data collection to produce generalizable dexterous policies without any robot data or online learning.
              Morphology-agnostic data, represented as 3D fingertip keypoints in camera frame (Figure a), is collected directly from a human demon-
              strator (Figure b) and used to train keypoint-based Transformer policies (Figure c). These policies, retargeted to our Allegro Hand + Franka
              Arm with inverse kinematics, generalize to unseen object poses and positions with high success rates.</p>
          </div>
        </div>
      </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">Data Collection and Deployment Hardware</h2>
            <div class="has-text-centered">
                <img src="./static/images/harware.jpg" alt="Hardware Setup" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">We collect fingertips in wrist frame with Manus Metagloves and map them to camera frame with an ArUco tag. In inference, we get fingertips in base frame with forward kinematics and map them to camera frame by calibrating a camera against the robot base. We use an Allegro Hand mounted on Franka Arm to deploy our policies.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">Closed-loop Policy</h2>
            <div class="has-text-centered">
                <img src="./static/images/closed_loop_policy.jpg" alt="Close-loop Policy" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">The state representation is a concatenation of end-effector and object keypoints. The end-effector keypoints
                  are the 3D coordinates of the index, middle, ring, and thumb fingers. The object keypoints are a set of 2D pixels, mapped to starting frames
                  with a correspondence model and to subsequent frames with a point tracker model, then unprojected into 3D. A queue of past states is fed
                  into the policy, which predicts the next end-effector points. During inference, the robot joint angles are recovered with inverse kinematics.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">From Human to Robot</h2>
            <div class="has-text-centered">
                <img src="./static/images/tasks.png" alt="From Human to Robot" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">Human demonstrations compared to successful robot policy rollouts on our three manipulation tasks:
                  picking and placing block, collecting balls in basket, and opening oven.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 style="margin-bottom: 1em ;" class="title is-3">Policy Rollouts</h2>
          <div class="content">
            <p>In the videos below you can see BATON solve three tasks.</p>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Pick and Place Block Example 1</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/pickblock1.mp4" type="video/mp4">
            </video>
            <p class="caption"><p class="caption">The robot picks and places a block in a specified location. This run demonstrates one initialization of the object.</p></p>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Pick and Place Block Example 2</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/pickblock2.mp4" type="video/mp4">
            </video>
            <p class="caption">The robot picks and places a block in a specified location. This run demonstrates a different object initialization.</p>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Open Oven Example 1</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%"> 
              <source src="./static/videos/openoven1.mp4" type="video/mp4">
            </video>
            <p class="caption">The robot opens the oven door successfully. This run demonstrates one initialization of the oven.</p>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Open Oven Example 2</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%"> 
              <source src="./static/videos/openoven2.mp4" type="video/mp4">
            </video>
            <p class="caption">The robot opens the oven door successfully. This run demonstrates a different oven initialization.</p>
          </div>
        </div>

      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Collect Balls in Basket Example 1</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/tennisball1.mp4" type="video/mp4">
            </video>
            <p class="caption">The robot collects tennis balls and places them in the basket. This run demonstrates one initialization of the balls.</p>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Collect Balls in Basket Example 2</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/tennisball2.mp4" type="video/mp4">
            </video>
            <p class="caption">The robot collects tennis balls and places them in the basket. This run demonstrates a different initialization of the balls.</p>
          </div>
        </div>
        
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <h3 class="title is-4">Open Unseen Oven</h3>
            <video id="dollyzoom" controls muted loop playsinline height="100%">
              <source src="./static/videos/openovenood.mp4" type="video/mp4">
            </video>
            <p class="caption">Baton is capable of generalization to fully novel objects unseen during training. The visual correspondence model is able
              to correspond keypoints from microwaves with entirely different colors, shapes, and handle design. Our 3D keypoint representation is
              invariant to these shifts and our large-scale data enables generalization.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">Scaling Laws</h2>
            <div class="has-text-centered">
                <img src="./static/images/ovenscaling.png" alt="Scaling Laws" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">We show scaling laws in terms of success rate increases
                  per unit of human hours. Baton increases in robustness with more
                  data motivating the need for a highly scalable data collection.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">Results</h2>
            <div class="has-text-centered">
                <img src="./static/images/task_success_rate.jpg" alt="Success rate" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">Success rate across tasks, evaluated on novel object poses
                  unseen in training. Each model was trained on demos from 90
                  minutes of data collection per task..</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">Compare to Teleoperation</h2>
            <div class="has-text-centered">
                <img src="./static/images/demorate.png" alt="Compare to Teleoperation" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">We compare the average data throughput of Baton in terms of demonstration per minute compared to VR teleoperation across
                  two tasks. Baton achieves higher throughput in both demonstration and session rates.</p>
            </div>
            <div class="has-text-centered">
              <img src="./static/images/demotime.png" alt="Compare to Teleoperation" style="max-width: 60%; height: auto;">
              <p class="is-size-6 has-text-grey">Average time in seconds of a demonstration collected by
                Baton compared to VR Teleoperation. Baton yields improvements
                in demonstration collection speed of over 2x for open oven and
                over 4x for pick and place block.</p>
            </div>
            <div class="has-text-centered">
              <img src="./static/images/trajectory.jpg" alt="Compare to Teleoperation" style="max-width: 60%; height: auto;">
              <p class="is-size-6 has-text-grey">Comparison of trajectories: (a) Human demonstrations
                are smooth and direct, while (b) teleoperated trajectories are er-
                ratic and less efficient due to latency and lack of natural embodi-
                ment.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class = "container is-max-desktop">
      <div class = "columns is-centered">
        <div class="column is-full-width">
          <div class="content">
            <h2 style="margin-bottom: 1em ;" class="title is-3">Compare to other methods</h2>
            <div class="has-text-centered">
                <img src="./static/images/compare_methods.jpg" alt="Compare to other methods" style="max-width: 60%; height: auto;">
                <p class="is-size-6 has-text-grey">Comparison of data collection methods on various scalability criteria. “Passive” refers to the ability of a human demonstrator to
                  collect data in their own embodiment without any extra overhead in terms of how the task should be done naturally.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>